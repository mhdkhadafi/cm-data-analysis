{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langdetect import detect\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('all_tweets'):\n",
    "    os.makedirs('all_tweets')\n",
    "    \n",
    "f_in = open('movie_tweet.txt', 'r')\n",
    "line = f_in.readline()\n",
    "# print line\n",
    "j = json.loads(line)\n",
    "movie_tweets = j[\"movie_tweet\"]\n",
    "for movie_tweet in movie_tweets:\n",
    "    title = movie_tweet[\"title\"]\n",
    "#     if title == 'paul blart' or title == 'true story' or title == 'unfriended':\n",
    "#         continue\n",
    "#     print title\n",
    "    f_out = open('all_tweets/all_tweet_' + title + '.txt', 'w')\n",
    "    output = []\n",
    "    tweets = movie_tweet[\"tweets\"]\n",
    "#     print len(tweets)\n",
    "    a = 0\n",
    "    for tweet in tweets:\n",
    "        if tweet[\"text\"] == \"Unfriended@RileyHaralson\":\n",
    "            tweet_out = {\"created_at\": tweet[\"created_at\"], \"text\": tweet[\"text\"], \"language\": \"en\"}\n",
    "        else:\n",
    "            tweet_out = {\"created_at\": tweet[\"created_at\"], \"text\": tweet[\"text\"], \"language\": detect(tweet[\"text\"])}\n",
    "        output.append(tweet_out)\n",
    "#         if len(output) % 100 == 0:\n",
    "#             print len(output)\n",
    "    f_out.write(json.dumps(output))\n",
    "    f_out.close()\n",
    "f_in.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies = ['alex of venice', 'beyond the reach', 'child 44', 'dead lands', 'felix and meira', 'monkey kingdom',\n",
    "          'monsters', 'paul blart', 'true story', 'unfriended']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('just_tweets'):\n",
    "    os.makedirs('just_tweets')\n",
    "    \n",
    "for movie in movies:\n",
    "    f_in = open('all_tweets/all_tweet_' + movie + '.txt', 'r')\n",
    "    line = f_in.readline()\n",
    "    tweets = json.loads(line)\n",
    "    \n",
    "    f_out = open('just_tweets/just_tweet_' + movie + '.txt', 'w')\n",
    "    \n",
    "    jt = []\n",
    "    for tweet in tweets:\n",
    "        jt.append(tweet[\"text\"])\n",
    "    \n",
    "    f_out.write(json.dumps(jt))\n",
    "    f_out.close()\n",
    "    f_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('split_tweets'):\n",
    "    os.makedirs('split_tweets')\n",
    "    \n",
    "chunk = [1, 1, 1, 1, 1, 1, 2, 10, 10, 30]\n",
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "for i in range(0, len(movies)):\n",
    "    f_in = open('just_tweets/just_tweet_' + movies[i] + '.txt', 'r')\n",
    "    line = f_in.readline()\n",
    "    json_tweet = json.loads(line)\n",
    "\n",
    "    json_tweet2 = chunks(json_tweet, len(json_tweet)/chunk[i])\n",
    "    for j in range(0, len(json_tweet2)):\n",
    "        f_out = open('split_tweets/split_tweet_' + movies[i] + '_' + str(j) + '.txt', 'w')\n",
    "        f_out.write(json.dumps(json_tweet2[j]))\n",
    "        f_out.close()\n",
    "\n",
    "    f_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('sentiment_tweets'):\n",
    "    os.makedirs('sentiment_tweets')\n",
    "    \n",
    "def sentiment_analysis(tw):\n",
    "    url = 'http://sentiment.vivekn.com/api/batch/'\n",
    "    headers = {'content-type': 'application/json'}\n",
    "\n",
    "    response = requests.post(url, data=json.dumps(tw), headers=headers)\n",
    "    return response.text\n",
    "\n",
    "for i in range(0, len(movies)):\n",
    "    f_out = open('sentiment_tweets/sentiment_tweet_' + movies[i] + '.txt', 'w')\n",
    "    output = {\"tweets\": []}\n",
    "\n",
    "    if chunk[i] <= 2:\n",
    "        chunk[i] -= 1\n",
    "    for a in range(0, chunk[i]+1):\n",
    "        f_in = open('split_tweets/split_tweet_' + movies[i] + '_' + str(a) + '.txt', 'r')\n",
    "\n",
    "        line = f_in.readline()\n",
    "        # print line\n",
    "        json_tweet = json.loads(line)\n",
    "        # print j\n",
    "        sentiment = sentiment_analysis(json_tweet)\n",
    "        json_sentiment = json.loads(sentiment)\n",
    "\n",
    "\n",
    "        for j in range(0, len(json_tweet)):\n",
    "            tweet_output = {\"text\": json_tweet[j], \"sentiment\": json_sentiment[j][\"result\"],\n",
    "                            \"confidence\": json_sentiment[j][\"confidence\"]}\n",
    "            output[\"tweets\"].append(tweet_output)\n",
    "        f_in.close()\n",
    "\n",
    "    f_out.write(json.dumps(output))\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('complete_tweets'):\n",
    "    os.makedirs('complete_tweets')\n",
    "    \n",
    "for movie in movies:\n",
    "    f_in = open('all_tweets/all_tweet_' + movie + '.txt', 'r')\n",
    "    line = f_in.readline()\n",
    "    j = json.loads(line)\n",
    "\n",
    "    f_in2 = open('sentiment_tweets/sentiment_tweet_' + movie + '.txt', 'r')\n",
    "    line2 = f_in2.readline()\n",
    "    j2 = json.loads(line2)\n",
    "    j2 = j2[\"tweets\"]\n",
    "\n",
    "    f_out = open('complete_tweets/complete_tweet_' + movie + \".txt\", 'w')\n",
    "\n",
    "    output = {\"movie\": movie, \"tweets\": []}\n",
    "    for i in range(0, len(j)):\n",
    "        tweet_out = {\"created_at\": j[i][\"created_at\"], \"text\": j[i][\"text\"], \"language\": j[i][\"language\"],\n",
    "                     \"sentiment\" : j2[i][\"sentiment\"], \"confidence\" : j2[i][\"confidence\"]}\n",
    "        output[\"tweets\"].append(tweet_out)\n",
    "\n",
    "    f_out.write(json.dumps(output))\n",
    "    f_out.close()\n",
    "    f_in.close()\n",
    "    f_in2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('filtered_tweets'):\n",
    "    os.makedirs('filtered_tweets')\n",
    "    \n",
    "utc=pytz.UTC\n",
    "\n",
    "for movie in movies:\n",
    "    f_in = open('complete_tweets/complete_tweet_' + movie + \".txt\", 'r')\n",
    "    line = f_in.readline()\n",
    "    tweets = json.loads(line)[\"tweets\"]\n",
    "\n",
    "    f_out = open('filtered_tweets/filtered_tweet_' + movie + \".txt\", 'w')\n",
    "\n",
    "    output = {\"movie\": movie, \"sentiments\": []}\n",
    "    start_date = datetime.datetime(2015,4,16,13,36,0)\n",
    "    end_date = datetime.datetime(2015,4,24,9,36,0)\n",
    "    date = start_date\n",
    "    sentiment = 0\n",
    "    num_tweet = 0\n",
    "    current_tweet = 0\n",
    "\n",
    "    while date <= end_date:\n",
    "        if current_tweet < len(tweets):\n",
    "            if parser.parse(tweets[current_tweet][\"created_at\"]) > utc.localize(date):\n",
    "                if num_tweet != 0:\n",
    "                    sentiment /= num_tweet\n",
    "                sentiment_output = {\"created_at\": str(utc.localize(date)), \"sentiment\": sentiment}\n",
    "                output[\"sentiments\"].append(sentiment_output)\n",
    "                date = date + datetime.timedelta(minutes=10)\n",
    "                sentiment = 0\n",
    "                num_tweet = 0\n",
    "            else:\n",
    "                if tweets[current_tweet][\"language\"] == 'en':\n",
    "                    if tweets[current_tweet][\"sentiment\"] == 'Negative':\n",
    "                        sentiment += (100 - float(tweets[current_tweet][\"confidence\"]))\n",
    "                    elif tweets[current_tweet][\"sentiment\"] == 'Neutral':\n",
    "                        sentiment += 50\n",
    "                    else:\n",
    "                        sentiment += float(tweets[current_tweet][\"confidence\"])\n",
    "                    num_tweet += 1\n",
    "\n",
    "                # sentiment_output = {\"created_at\": str(utc.localize(date)), \"sentiment\": sentiment}\n",
    "                # output[\"sentiments\"].append(sentiment_output)\n",
    "                current_tweet += 1\n",
    "        else:\n",
    "            if num_tweet != 0:\n",
    "                sentiment /= num_tweet\n",
    "            sentiment_output = {\"created_at\": str(utc.localize(date)), \"sentiment\": sentiment}\n",
    "            output[\"sentiments\"].append(sentiment_output)\n",
    "            date = date + datetime.timedelta(minutes=10)\n",
    "            sentiment = 0\n",
    "            num_tweet = 0\n",
    "\n",
    "    f_out.write(json.dumps(output))\n",
    "    f_out.close()\n",
    "    f_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('zero_fitted_tweets'):\n",
    "    os.makedirs('zero_fitted_tweets')\n",
    "\n",
    "def fit_list(sent):\n",
    "    sent[0] = 1\n",
    "    for i in range(0, len(sent)-1):\n",
    "        if sent[i] != 0 and sent[i+1] == 0:\n",
    "            for j in range(i+1, len(sent)):\n",
    "                if sent[j] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    y1 = sent[i]\n",
    "                    y2 = sent[j]\n",
    "                    x1 = i\n",
    "                    x2 = j\n",
    "                    m = (y2-y1) / (x2-x1)\n",
    "                    c = y1 - (m*x1)\n",
    "\n",
    "                    for k in range(i, j):\n",
    "                        sent[k] = (m*k) + c\n",
    "                    break\n",
    "    return sent\n",
    "\n",
    "for movie in movies:\n",
    "    f_in = open('filtered_tweets/filtered_tweet_' + movie + \".txt\", 'r')\n",
    "    line = f_in.readline()\n",
    "    sentiments = json.loads(line)[\"sentiments\"]\n",
    "\n",
    "    f_out = open('zero_fitted_tweets/zero_fitted_tweet_' + movie + \".txt\", 'w')\n",
    "\n",
    "    output = {\"movie\": movie, \"sentiments\": []}\n",
    "    sentiment_list = []\n",
    "    for sentiment in sentiments:\n",
    "        sentiment_list.append(sentiment[\"sentiment\"])\n",
    "\n",
    "    sentiment_list = fit_list(sentiment_list)\n",
    "\n",
    "    for i in range(0, len(sentiments)):\n",
    "        sentiment_output = {\"created_at\": sentiments[i][\"created_at\"], \"sentiment\": sentiment_list[i]}\n",
    "        output[\"sentiments\"].append(sentiment_output)\n",
    "\n",
    "    f_out.write(json.dumps(output))\n",
    "    f_out.close()\n",
    "    f_in.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
